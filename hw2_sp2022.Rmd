---
title: "Modern Data Mining, HW 2"
author:
- Group Member 1
- Group Member 2
- Group Member 3
date: 'Due: 11:59 PM,  Sunday, 02/12'
output:
  html_document:
    code_folding: show
    highlight: haddock
    number_sections: yes
    theme: lumen
    toc: yes
    toc_depth: 4
    toc_float: yes
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: '4'
  word_document:
    toc: yes
    toc_depth: '4'
urlcolor: blue
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.width=8, fig.height=4)
options(scipen = 0, digits = 3)  # controls base R output
# check if you have ISLR package, if not, install it
if(!require('pacman')) {install.packages('pacman')}
pacman::p_load(ISLR, tidyverse, data.table) # add the packages needed
```


\pagebreak

# Overview {-}

Principle Component Analysis is widely used in data exploration, dimension reduction, data visualization. The aim is to transform original data into uncorrelated linear combinations of the original data while keeping the information contained in the data. High dimensional data tends to show clusters in lower dimensional view. 

Clustering Analysis is another form of EDA. Here we are hoping to group data points which are close to each other within the groups and far away between different groups. Clustering using PC's can be effective. Clustering analysis can be very subjective in the way we need to summarize the properties within each group. 

Both PCA and Clustering Analysis are so called unsupervised learning. There is no response variables involved in the process. 

For supervised learning, we try to find out how does a set of predictors relate to some response variable of the interest. Multiple regression is still by far, one of the most popular methods. We use a linear models as a working model for its simplicity and interpretability. It is important that we use domain knowledge as much as we can to determine the form of the response as well as the function format of the factors on the other hand. 


## Objectives

- PCA
- SVD
- Clustering Analysis
- Linear Regression

## Review materials

- Study Module 2: PCA
- Study Module 3: Clustering Analysis
- Study Module 4: Multiple regression

## Data needed

- `NLSY79.csv`
- `brca_subtype.csv`
- `brca_x_patient.csv`

# Case study 1: Self-seteem 

Self-esteem generally describes a person's overall sense of self-worthiness and personal value. It can play significant role in one's motivation and success throughout the life. Factors that influence self-esteem can be inner thinking, health condition, age, life experiences etc. We will try to identify possible factors in our data that are related to the level of self-esteem. 

In the well-cited National Longitudinal Study of Youth (NLSY79), it follows about 13,000 individuals and numerous individual-year information has been gathered through surveys. The survey data is open to public [here](https://www.nlsinfo.org/investigator/). Among many variables we assembled a subset of variables including personal demographic variables in different years, household environment in 79, ASVAB test Scores in 81 and Self-Esteem scores in 81 and 87 respectively. 

The data is store in `NLSY79.csv`.



Here are the description of variables:

**Personal Demographic Variables**

* Gender: a factor with levels "female" and "male"
* Education05: years of education completed by 2005
* HeightFeet05, HeightInch05: height measurement. For example, a person of 5'10 will be recorded as HeightFeet05=5, HeightInch05=10.
* Weight05: weight in lbs.
* Income87, Income05: total annual income from wages and salary in 2005. 
* Job87 (missing), Job05: job type in 1987 and 2005, including Protective Service Occupations, Food Preparation and Serving Related Occupations, Cleaning and Building Service Occupations, Entertainment Attendants and Related Workers, Funeral Related Occupations, Personal Care and Service Workers, Sales and Related Workers, Office and Administrative Support Workers, Farming, Fishing and Forestry Occupations, Construction Trade and Extraction Workers, Installation, Maintenance and Repairs Workers, Production and Operating Workers, Food Preparation Occupations, Setters, Operators and Tenders,  Transportation and Material Moving Workers
 
 
**Household Environment**
 
* Imagazine: a variable taking on the value 1 if anyone in the respondent’s household regularly read magazines in 1979, otherwise 0
* Inewspaper: a variable taking on the value 1 if anyone in the respondent’s household regularly read newspapers in 1979, otherwise 0
* Ilibrary: a variable taking on the value 1 if anyone in the respondent’s household had a library card in 1979, otherwise 0
* MotherEd: mother’s years of education
* FatherEd: father’s years of education
* FamilyIncome78

**Variables Related to ASVAB test Scores in 1981**

Test | Description
--------- | ------------------------------------------------------
AFQT | percentile score on the AFQT intelligence test in 1981 
Coding | score on the Coding Speed test in 1981
Auto | score on the Automotive and Shop test in 1981
Mechanic | score on the Mechanic test in 1981
Elec | score on the Electronics Information test in 1981
Science | score on the General Science test in 1981
Math | score on the Math test in 1981
Arith | score on the Arithmetic Reasoning test in 1981
Word | score on the Word Knowledge Test in 1981
Parag | score on the Paragraph Comprehension test in 1981
Numer | score on the Numerical Operations test in 1981

**Self-Esteem test 81 and 87**

We have two sets of self-esteem test, one in 1981 and the other in 1987. Each set has same 10 questions. 
They are labeled as `Esteem81` and `Esteem87` respectively followed by the question number.
For example, `Esteem81_1` is Esteem question 1 in 81.

The following 10 questions are answered as 1: strongly agree, 2: agree, 3: disagree, 4: strongly disagree

* Esteem 1: “I am a person of worth”
* Esteem 2: “I have a number of good qualities”
* Esteem 3: “I am inclined to feel like a failure”
* Esteem 4: “I do things as well as others”
* Esteem 5: “I do not have much to be proud of”
* Esteem 6: “I take a positive attitude towards myself and others”
* Esteem 7: “I am satisfied with myself”
* Esteem 8: “I wish I could have more respect for myself”
* Esteem 9: “I feel useless at times”
* Esteem 10: “I think I am no good at all”

## Data preparation

Load the data. Do a quick EDA to get familiar with the data set. Pay attention to the unit of each variable. Are there any missing values? 

```{r quick skim of the data, eval = F, echo=FALSE}
temp <- read.csv('data/NLSY79.csv', header = T, stringsAsFactors = F)
# # missing values? real variables vs. factors? are varable values reasonable?
str(temp)
summary(temp)
levels(as.factor(temp$Job05))
table(as.factor(temp$Job05))
```
<p style="color:blue">
Observations:

* Some of the income values are negative -- this doesn't seem right.
* Many Jobs5 are missing values.
* Some of the HeightFeet05 are negative which doesn't make sense.
* A number of test score values are 0, which I would assume means these people never took these exams.
* All of the esteem columns seem to be missing no entries.
</p>

## Self esteem evaluation

Let concentrate on Esteem scores evaluated in 87. 

0. First do a quick summary over all the `Esteem` variables. Pay attention to missing values, any peculiar numbers etc. How do you fix problems discovered if there is any? Briefly describe what you have done for the data preparation. 

Observations:

<p style="color:blue">
* There are no missing values.
* The average of the possible respondent responses (1-4) is 2.5. However, all of the questions either skew agree (i.e., a 1.5 mean) or skew disagree (i.e., a 3.5 mean).
* One possible issue is that when a respondent responses agree, their response could indicate either low or high self esteem based on the question asked. For example, a person with strong self esteem would response with a low number (1 or 2) to a question like Question 1: “I am a person of worth” but with a high number (3 or 4) to a question like Question 5: “I do not have much to be proud of." We will solve this issue in the following step.
</p>

```{r summary over esteem variables, echo=TRUE} 
summary(temp$Esteem87_1)
summary(temp$Esteem87_2)
summary(temp$Esteem87_3)
summary(temp$Esteem87_4)
summary(temp$Esteem87_5)
summary(temp$Esteem87_6)
summary(temp$Esteem87_7)
summary(temp$Esteem87_8)
summary(temp$Esteem87_9)
summary(temp$Esteem87_10)
```

1. Reverse Esteem 1, 2, 4, 6, and 7 so that a higher score corresponds to higher self-esteem. (Hint: if we store the esteem data in `data.esteem`, then `data.esteem[,  c(1, 2, 4, 6, 7)]  <- 5 - data.esteem[,  c(1, 2, 4, 6, 7)]` to reverse the score.)

```{r reversing some of the responses, echo=TRUE} 
data.esteem <- data.frame(temp$Esteem87_1,temp$Esteem87_2,temp$Esteem87_3,temp$Esteem87_4,temp$Esteem87_5,temp$Esteem87_6,temp$Esteem87_7,temp$Esteem87_8,temp$Esteem87_9,temp$Esteem87_10)

colnames(data.esteem)[1] = "q1"
colnames(data.esteem)[2] = "q2"
colnames(data.esteem)[3] = "q3"
colnames(data.esteem)[4] = "q4"
colnames(data.esteem)[5] = "q5"
colnames(data.esteem)[6] = "q6"
colnames(data.esteem)[7] = "q7"
colnames(data.esteem)[8] = "q8"
colnames(data.esteem)[9] = "q9"
colnames(data.esteem)[10] = "q10"

data.esteem[, c(1,2,4,6,7)] <- 5 - data.esteem[, c(1,2,4,6,7)]
```

2. Write a brief summary with necessary plots about the 10 esteem measurements.

* <p style="color:blue"> Plotting the respondents responses using a stacked bar graph we see that most respondents have higher self esteem and that very few respondents were putting 1s (less than 500) compared to 4s (greater than 10,000). <p>
* <p style="color:blue"> Question 2 has the highest mean (3.6), while Question 9 has the lowest mean (3.06). </p>


```{r brief summary, echo=FALSE}
data.esteemMelt <- melt(data.esteem)

g <- ggplot(data.esteemMelt, aes(x=value, fill=variable )) + geom_bar(position = "stack")
g

summary(data.esteem$q1)
summary(data.esteem$q2)
summary(data.esteem$q3)
summary(data.esteem$q4)
summary(data.esteem$q5)
summary(data.esteem$q6)
summary(data.esteem$q7)
summary(data.esteem$q8)
summary(data.esteem$q9)
summary(data.esteem$q10)

```

3. Do esteem scores all positively correlated? Report the pairwise correlation table and write a brief summary.

* There is a positive coorelation between all esteem scores. This reachnes from 0.24 (q1 and q9) to 0.7 (q1 and q2).

```{r correlation table, eval = F, echo=TRUE} 
data.esteem
res <- cor(data.esteem)
round(res, 2)
```

4. PCA on 10 esteem measurements. (centered but no scaling)

```{r pca}
pc.10 <- prcomp(data.esteem, scale=TRUE)
names(pc.10)
```

    a) Report the PC1 and PC2 loadings. Are they unit vectors? Are they orthogonal? 
    
* <p style="color:blue"> The two loadings are orthoginal with unit 1. <p>
    
```{r loadings}
pc.10.loading <- pc.10$rotation
knitr::kable(pc.10.loading)

pc.10.loading[,1] # pc1 loadings
pc.10.loading[,2] # pc2 loadings
```
    
    b) Are there good interpretations for PC1 and PC2? (If loadings are all negative, take the positive loadings for the ease of interpretation)
    
* <p style="color:blue"> PC1 interpretation: all of the coefficients are positive and around 0.3. This means there is a positive correlation between almost oll of the variables. So a growing positive alue in PC1 means a rather uniform gorwth of values in al of the varirables and this means that as much a person has a higher value in PC1, they are likeley to have a higher response/answer (1-4) to almost all of the 10 questions. This says that the higher a person's response (1-4) to the 10 questions, the higher their self-esteem, which makes sense. Since all of the coefficients are around 0.3, PC1 is proportional to the total of the 10 answers/responses. </p>

* <p style="color:blue"> PC 2 interpretation: </p>
  
    c) How is the PC1 score obtained for each subject? Write down the formula.
    
* <p style="color:blue"> The PC1 is the linear combination of the 10 scores which minimizes the total squared perpendicular distance. </p>
* <p style="color:blue"> for each subject, their PC1 score is 0.324 x (q1 response) + 0.333 x (q2 response) + 0.322 x (q3 response) + 0.324 x (q4 response) + 0.315 x (q5 response) + 0.347 x (q6 response) + 0.315 x (q7 response) + 0.280 x (q8 response) + 0.277 x (q9 response) + 0.318 x (q10 response). </p>
    
    d) Are PC1 scores and PC2 scores in the data uncorrelated? 
    
* <p style="color:blue"> Yes the PC1 scores and PC2 scores are uncorrelated. PC1 scores has greater variance than PC2 scores. </p>
    
    e) Plot PVE (Proportion of Variance Explained) and summarize the plot. 
    
* <p style="color:blue"> From a scree plot of the variances of each pc we see that a large portion of the total variance is explained by the leading principle component (0.469 of the total variance). The variances of each PC are decreasing (i.e., 0.469 from PC1 while 0.0294 from PC10). </p>
    
```{r pve, echo=TRUE}
summary(pc.10)$importance
plot(pc.10) # variances of each pc


plot(summary(pc.10)$importance[2,], # scree plot of PVEs
     ylab="PVE",
     xlab="Number of PCs",
     pch = 16,
     main="Scree plot of PVE")

```
  
    f) Also plot CPVE (Cumulative Proportion of Variance Explained). What proportion of the variance in the data is explained by the first two principal components?
    
* <p style="color:blue"> Plotting the CPVE, we see that 0.59 of the total variance in the data is explained by the first two principal components. </p>
  
```{r cpve, echo=TRUE}

plot(summary(pc.10)$importance[3,],
     ylab="Cumulative PVE",
     xlab="Number of PCs",
     pch = 16,
     main="Scree plot of Cumulative PVE")
```
    
  
    g) PC’s provide us with a low dimensional view of the self-esteem scores. Use a biplot with the first two PC's to display the data.  Give an interpretation of PC1 and PC2 from the plot. (try `ggbiplot` if you could, much prettier!)
    
    
* <p style="color:blue"> A biplot with PC1 and PC2 indicated that a) PC1 loadings are similar in magnitudes and with same signs, b) PC2 captures difference between total of question 8, 9, and 10 and total of question 1, 2, and 4. Questions 3, 5, 6, 7 have little affect, c) questions 8, 9, and 10 are highly correlated and so are questions 1, 2, and 4. </p>
    
    
```{r biplot of first two PCs, echo=TRUE} 
limx <- c(-0,0.03)
limy <- c(-0.05,0.05)
biplot(pc.10,
       xlim=limx,
       ylim=limy,
       main="Biplot of PC1 and PC2")
```

5. Apply k-means to cluster subjects on the original esteem scores

    a) Find a reasonable number of clusters using within sum of squared with elbow rules.

* <p style="color:blue"> Based on the "Elbow method" and the result of our factoextra::fviz_nbclust call, we will use k=2 to have two clusters. </p> 
    
```{r number of clusters via elbow method, echo=TRUE} 
set.seed(0)
factoextra::fviz_nbclust(data.esteem[,-1], kmeans, method = "wss")
```
    
    b) Can you summarize common features within each cluster?
    
    * Participants within each cluster will have had similar responses to the 10 questions as others in their cluster.
    
    c) Can you visualize the clusters with somewhat clear boundaries? You may try different pairs of variables and different PC pairs of the esteem scores.
    
```{r visualize the clusters, echo=TRUE} 
 as.data.frame(pc.10$x) %>%
  ggplot(aes(x=PC1, y=PC10)) +
  geom_point()+
  geom_vline(xintercept = 0) +
  geom_hline(yintercept = 0) +
  ggtitle("PC2 vs. PC1") +
  theme_bw()
pairs(pc.10$x, xlim=c(-4, 4), ylim=c(-4, 4), col=rainbow(6), pch=16)

```


6. We now try to find out what factors are related to self-esteem? PC1 of all the Esteem scores is a good variable to summarize one's esteem scores. We take PC1 as our response variable. 

    a) Prepare possible factors/variables:
    
      - EDA the data set first. 

      - Personal information: gender, education (05), log(income) in 87, job type in 87. Weight05 (lb) and HeightFeet05 together with Heightinch05. One way to summarize one's weight and height is via Body Mass Index which is defined as the body mass divided by the square of the body height, and is universally expressed in units of kg/m². Note, you need to create BMI first. Then may include it as one possible predictor. 
          
      - Household environment: Imagazine, Inewspaper, Ilibrary, MotherEd, FatherEd, FamilyIncome78. Do set indicators `Imagazine`, `Inewspaper` and `Ilibrary` as factors. 
    
      - You may use PC1 of ASVAB as level of intelligence
      
```{r 1 6a, echo=TRUE}
# eda
esteemFactors <- data.frame(temp$Gender, temp$Education05, temp$Income87, temp$Job05, temp$Weight05, temp$HeightFeet05, temp$HeightInch05, factor(temp$Imagazine), factor(temp$Inewspaper), factor(temp$Ilibrary), temp$MotherEd, temp$FatherEd, temp$FamilyIncome78)
esteemFactors$totalHeightMeters5 <- ((esteemFactors$temp.HeightFeet05 * 12)+ esteemFactors$temp.HeightInch05) *  0.0254
esteemFactors$BMI05 <- (esteemFactors$temp.Weight05 * 0.453592) / (esteemFactors$totalHeightMeters5^2)
pc.10.loading[,1] # 0.324 0.333 0.322 0.324 0.315 0.347 0.315 0.280 0.277 0.318 
esteemFactors$PC1 <- data.frame(data.esteem$q1 * 0.324 + data.esteem$q2 * 0.333 + data.esteem$q3 * 0.322 + data.esteem$q4 * 0.324 + data.esteem$q5 * 0.315 + data.esteem$q6 * 0.347 + data.esteem$q7 * 0.315 + data.esteem$q8 * 0.280 + data.esteem$q9 * 0.277 + data.esteem$q10 * 0.318)
colnames(esteemFactors)[1] = "gender"
colnames(esteemFactors)[2] = "Education05"
colnames(esteemFactors)[3] = "Income87"
colnames(esteemFactors)[4] = "Job05"
colnames(esteemFactors)[5] = "Weight05"
colnames(esteemFactors)[6] = "HeightFeet05"
colnames(esteemFactors)[7] = "HeightInch05"
colnames(esteemFactors)[8] = "Imagazine"
colnames(esteemFactors)[9] = "Inewspaper"
colnames(esteemFactors)[10] = "Ilibrary"
colnames(esteemFactors)[11] = "MotherEd"
colnames(esteemFactors)[12] = "FatherEd"
colnames(esteemFactors)[13] = "FamilyIncome78"
colnames(esteemFactors)[16] = "PC1"

data.ASVAB <- data.frame(temp$Science,temp$Arith,temp$Word,temp$Parag,temp$Number,temp$Coding,temp$Auto,temp$Math,temp$Mechanic,temp$Elec,temp$AFQT)

pc.ASVAB <- prcomp(data.ASVAB, scale=TRUE)
pc.ASVAB.loading <- pc.ASVAB$rotation
knitr::kable(pc.ASVAB.loading)
pc.ASVAB.loading[,1] # 0.328 0.336 0.330 0.310 0.255 0.217 0.247 0.322 0.291 0.297 0.353 
esteemFactors$PC1ASVAB <- data.frame(temp$Science*0.328+temp$Arith*0.336+temp$Word*0.330+temp$Parag*0.310+temp$Number*0.255+temp$Coding*0.217+temp$Auto*0.247+temp$Math*0.322+temp$Mechanic*0.291+temp$Elec*0.297+temp$AFQT*0.353)
``` 
        
    b)   Run a few regression models between PC1 of all the esteem scores and suitable variables listed in a). Find a final best model with your own criterion. 

      - How did you land this model? Run a model diagnosis to see if the linear model assumptions are reasonably met. 
        
      - Write a summary of your findings. In particular, explain what and how the variables in the model affect one's self-esteem. 

We chose the model with all variables. Running a model diagnosis, we see that both the Residuals vs Fitted and qqnormal plots look fine.

```{r regression models, echo=TRUE}
fit1 <- lm(unlist(PC1) ~ unlist(PC1ASVAB), data=esteemFactors)
fit2 <- lm(unlist(PC1) ~ Education05, data=esteemFactors)
fit3 <- lm(unlist(PC1) ~ FamilyIncome78, data=esteemFactors)
fit.all <- lm(unlist(PC1) ~ unlist(PC1ASVAB) + gender + Education05 + Income87 + Job05 + Weight05 + HeightFeet05 + HeightInch05 + Imagazine + Inewspaper + Ilibrary + MotherEd + FatherEd + FamilyIncome78 + totalHeightMeters5 + BMI05 + unlist(PC1ASVAB), data=esteemFactors)

summary(fit1)
summary(fit2)
summary(fit.all)
anova(fit.all)
par(mfrow=c(1,2))
plot(fit.all, 1)
plot(fit.all, 2)
```

# Case study 2: Breast cancer sub-type


[The Cancer Genome Atlas (TCGA)](https://www.cancer.gov/about-nci/organization/ccg/research/structural-genomics/tcga), a landmark cancer genomics program by National Cancer Institute (NCI), molecularly characterized over 20,000 primary cancer and matched normal samples spanning 33 cancer types. The genome data is open to public from the [Genomic Data Commons Data Portal (GDC)](https://portal.gdc.cancer.gov/).
 
In this study, we focus on 4 sub-types of breast cancer (BRCA): basal-like (basal), Luminal A-like (lumA), Luminal B-like (lumB), HER2-enriched. The sub-type is based on PAM50, a clinical-grade luminal-basal classifier. 

* Luminal A cancers are low-grade, tend to grow slowly and have the best prognosis.
* Luminal B cancers generally grow slightly faster than luminal A cancers and their prognosis is slightly worse.
* HER2-enriched cancers tend to grow faster than luminal cancers and can have a worse prognosis, but they are often successfully treated with targeted therapies aimed at the HER2 protein. 
* Basal-like breast cancers or triple negative breast cancers do not have the three receptors that the other sub-types have so have fewer treatment options.

We will try to use mRNA expression data alone without the labels to classify 4 sub-types. Classification without labels or prediction without outcomes is called unsupervised learning. We will use K-means and spectrum clustering to cluster the mRNA data and see whether the sub-type can be separated through mRNA data.

We first read the data using `data.table::fread()` which is a faster way to read in big data than `read.csv()`. 

```{r}
brca <- fread("data/brca_subtype.csv")

# get the sub-type information
brca_subtype <- brca$BRCA_Subtype_PAM50
brca <- brca[,-1]
```

1. Summary and transformation

    a) How many patients are there in each sub-type? 

```{r 2 1a, echo=TRUE}
table(brca_subtype)
```

    b) Randomly pick 5 genes and plot the histogram by each sub-type.

```{r 2 1b,, echo=TRUE}


num_gene <- ncol(brca)
# randomly select 10 gene
set.seed(10)
sample_idx <- sample(num_gene, 5)
# plot count number histogram for each gene
brca %>%
select(all_of(sample_idx)) %>% # select column by index
pivot_longer(cols = everything()) %>% # for facet(0)
ggplot(aes(x = value, y = ..density..)) +
geom_histogram(aes(fill = name)) +
facet_wrap(~name, scales = "free") +
theme_bw() +
theme(legend.position = "none")
```

    c) Remove gene with zero count and no variability. Then apply logarithmic transform.

```{r 2 1c}
sel_cols <- which(colSums(abs(brca)) != 0)
brca_sub <- brca[, sel_cols, with=F]

brca_sub <- log2(as.matrix(brca_sub+1e-10))
```

2. Apply kmeans on the transformed dataset with 4 centers and output the discrepancy table between the real sub-type `brca_subtype` and the cluster labels.

```{r 2 2, echo=TRUE}
brca_sub_kmeans <- kmeans(x = brca_sub, 4)
#saveRDS(brca_sub_kmeans, "brca_kmeans.RDS")
#brca_sub_kmeans <- readRDS("output/brca_kmeans.RDS")

table(brca_subtype, brca_sub_kmeans$cluster)
```

3. Spectrum clustering: to scale or not to scale?

    a) Apply PCA on the centered and scaled dataset. How many PCs should we use and why? You are encouraged to use `irlba::irlba()`.

```{r 3a, echo=TRUE}
pca_ret <- prcomp(brca_sub, center = T, scale. = T)
pve <- summary(pca_ret)$importance[2, 1:10]
plot(pve, type="b", pch = 19, frame = FALSE)
```
According to the elbow rule, we should use 4 principal components as by that point the overwhelming majority of the variance is accounted for.
  
    b) Plot PC1 vs PC2 of the centered and scaled data and PC1 vs PC2 of the centered but unscaled data side by side. Should we scale or not scale for clustering process? Why? (Hint: to put plots side by side, use `gridExtra::grid.arrange()` or `ggpubr::ggrrange()` or `egg::ggrrange()` for ggplots; use `fig.show="hold"` as chunk option for base plots)

```{r 3b, echo=TRUE}
#Centered & Scaled
library(gridExtra)
p <- data.table(x = pca_ret$x[,1],
y = pca_ret$x[,2]) %>%
ggplot() +
geom_point(aes(x = x, y = y)) +
theme_bw() +
xlab("PC1") +
ylab("PC2") + 
ggtitle("Centered & Scaled")
p

pca_ret_centered_unscaled <- prcomp(brca_sub, center = T, scale. = F)
p2 <- data.table(x = pca_ret_centered_unscaled$x[,1],
y = pca_ret$x[,2]) %>%
ggplot() +
geom_point(aes(x = x, y = y)) +
theme_bw() +
xlab("PC1") +
ylab("PC2") + 
ggtitle("Centered but Unscaled")
p2

grid.arrange(p, p2, ncol = 2)
```

No, we already took the log of the data so I believe it is not necessary to scale the data since the log transform already helps handle skewness and asymmetries in the data.

4. Spectrum clustering: center but do not scale the data

    a) Use the first 4 PCs of the centered and unscaled data and apply kmeans. Find a reasonable number of clusters using within sum of squared with the elbow rule.
    
```{r 2 4a, echo=TRUE}
#kmean_ret <- kmeans(x = pca_ret_centered_unscaled$x[, 1:4], 4)
    
wss <- function(df, k) {
  kmeans(df, k, nstart = 10)$tot.withinss
}
    
k.values <- 1:10

wss_values <- sapply(k.values, 
                     function(k) kmeans(pca_ret_centered_unscaled$x[, 1:4], centers = k)$tot.withinss)
    

# extract wss for 1:10 clusters
wss_values <- map_dbl(k.values, function(k) wss(pca_ret_centered_unscaled$x[, 1:4], k))
plot(k.values, wss_values,
type="b", pch = 19, frame = FALSE,
xlab="Number of clusters K",
ylab="Total within-clusters sum of squares")
```
    
    b) Choose an optimal cluster number and apply kmeans. Compare the real sub-type and the clustering label as follows: Plot scatter plot of PC1 vs PC2. Use point color to indicate the true cancer type and point shape to indicate the clustering label. Plot the kmeans centroids with black dots. Summarize how good is clustering results compared to the real sub-type.
    
```{r 2 4b, echo=TRUE}
#Doesnt work
kmean_ret <- kmeans(x = pca_ret_centered_unscaled$x[, 1:4], 4)

p <- data.table(x = pca_ret_centered_unscaled$x[,1],
y = pca_ret_centered_unscaled$x[,2],
col = as.factor(brca_subtype),
cl = as.factor(kmean_ret$cluster)) %>%
ggplot() +
geom_point(aes(x = x, y = y, col = col, shape = cl)) +
geom_point(data = as.data.frame(kmean_ret$centers), aes(x = PC1, y = PC2), col = "black", shape = 21, size = 5) +
scale_color_manual(labels = c("LumA", "Her2", "Basal", "LumB"), 
values = scales::hue_pal()(4)) +
scale_shape_manual(labels = c("Cluster 1", "Cluster 2", "Cluster 3", "Cluster 4"),
values = c(4, 16,17,18)) +
theme_bw() +
labs(color = "Breast Cancer Sub-type", shape = "Cluster") +
xlab("PC1") +
ylab("PC2")

p

table(brca_subtype, kmean_ret$cluster)

```
The clustering seems to be able to generally discern the 4 subtypes into groups however it is not entirely accurate. There are definitely blurred regions and significant overlap where the results are not correct.

    c) Compare the clustering result from applying kmeans to the original data and the clustering result from applying kmeans to 4 PCs. Does PCA help in kmeans clustering? What might be the reasons if PCA helps?
    
<p style="color:blue"> Based on analysis of the discrepancy tables for both and the plot it seems that they agree quite well with each other. This means we can use the 3 principal components rather than all the dimensions in the original dataset. This makes the kmeans process more efficient, easier to interpret, and can lend better results. </p>
    
    d) Now we have an x patient with breast cancer but with unknown sub-type. We have this patient's mRNA sequencing data. Project this x patient to the space of PC1 and PC2. (Hint: remember we remove some gene with no counts or no variablity, take log and centered) Plot this patient in the plot in iv) with a black dot. Calculate the Euclidean distance between this patient and each of centroid of the cluster. Can you tell which sub-type this patient might have? 
    
```{r 2 3d, eval = F, echo=TRUE}
x_patient <- fread("data/brca_x_patient.csv")
x_patient

x_patient <- log2(as.matrix(x_patient+1e-10))
x_patient_centered <- t(t(x_patient) - rowMeans(x_patient))
pc1score <- pca_ret_centered_unscaled$x[,1] * x_patient_centered
```

# Simple Regression through simulations
    
## Linear model through simulations

This exercise is designed to help you understand the linear model using simulations. In this exercise, we will generate $(x_i, y_i)$ pairs so that all linear model assumptions are met.

Presume that $\mathbf{x}$ and $\mathbf{y}$ are linearly related with a normal error $\boldsymbol{\varepsilon}$ , such that $\mathbf{y} = 1 + 1.2\mathbf{x} + \boldsymbol{\varepsilon}$. The standard deviation of the error $\varepsilon_i$ is $\sigma = 2$. 

We can create a sample input vector ($n = 40$) for $\mathbf{x}$ with the following code:

```{r generate y vector, eval = F, echo = TRUE}
# Generates a vector of size 40 with equally spaced values between 0 and 1, inclusive
x <- seq(0, 1, length = 40)
set.seed(1)
y <- 1+1.2*x+rnorm(40,0,sd=2)
```


### Generate data

Create a corresponding output vector for $\mathbf{y}$ according to the equation given above. Use `set.seed(1)`. Then, create a scatterplot with $(x_i, y_i)$ pairs. Base R plotting is acceptable, but if you can, please attempt to use `ggplot2` to create the plot. Make sure to have clear labels and sensible titles on your plots.


### Understand the model
i. Find the LS estimates of $\boldsymbol{\beta}_0$ and $\boldsymbol{\beta}_1$, using the `lm()` function. What are the true values of $\boldsymbol{\beta}_0$ and $\boldsymbol{\beta}_1$? Do the estimates look to be good? 

From the `lm()` function, we get $\boldsymbol{\beta}_0 = 1.331$ and $\boldsymbol{\beta}_1 = 0.906$, vs true values of 1 and 1.2, so this isn't a perfect estimate, which is a result of the normal error with SD of 2.

```{r LS estimates, echo=TRUE}
x <- seq(0, 1, length = 40)
set.seed(1)
y <- 1+1.2*x+rnorm(40,0,sd=2)
pairs <- data.frame(x = x, y = y)
plot(x,y,
     main="sample output vector for y according to y = 1 + 1.2x + normal error with sd=2")
fit1 <- lm(y ~ x, data=pairs)
fit1
```

ii. What is your RSE for this linear model fit? Is it close to $\sigma = 2$? 

The RSE is 1.79 which is fairly close to 2 (10.3% off)

```{r rse of model, echo=TRUE}
rse <- summary(fit1)$sigma
rse
(rse-2)/2
```

iii. What is the 95% confidence interval for $\boldsymbol{\beta}_1$? Does this confidence interval capture the true $\boldsymbol{\beta}_1$?

```{r Confidence Interval, echo=TRUE}
summary(fit1)
```

The 95% CI is determined by the estimate +/- 1.96*SE. So here it would be .906 +/- 1.879: [-.973, 2.785]. Yes, this interval captures the true value of 1.2.

iv. Overlay the LS estimates and the true lines of the mean function onto a copy of the scatterplot you made above.


```{r LS estimates 4 124, echo=TRUE}
plot(pairs$x, pairs$y,
pch = 16,
xlab = "X",
ylab = "Y",
main = "Overlay of LS estimations and mean function")
abline(fit1, col="red", lwd=4) # many other ways.
abline(h=mean(pairs$y), lwd=5, col="blue") # add a horizontal line, y=mean(y)
```

### diagnoses

i. Provide residual plot where fitted $\mathbf{y}$-values are on the x-axis and residuals are on the y-axis. 

```{r Residual Plot and QQ plot, echo=TRUE}
plot(fit1)
```

ii. Provide a normal QQ plot of the residuals.

See part above 

iii. Comment on how well the model assumptions are met for the sample you used. 

The first assumption is linearity. The residuals seem to be relatively symmetric with respect to h=0 so this assumption is satisfied. The second assumption is homoscedasticity which also seems to be satsified as the residuals are evenly distributed across the band. Finally, the residuals seem to mostly fit the normal distribution according to the qq plot. However, there is some significant deviation at the bottom tail.

## Understand sampling distribution and confidence intervals

This part aims to help you understand the notion of sampling statistics and confidence intervals. Let's concentrate on estimating the slope only.  

Generate 100 samples of size $n = 40$, and estimate the slope coefficient from each sample. We include some sample code below, which should guide you in setting up the simulation. Note: this code is easier to follow but suboptimal; see the appendix for a more optimal R-like way to run this simulation.
```{r, eval = F, echo = TRUE}
# Inializing variables. Note b_1, upper_ci, lower_ci are vectors
x <- seq(0, 1, length = 40) 
n_sim <- 100              # number of simulations
b1 <- 0                   # n_sim many LS estimates of beta_1 (=1.2). Initialize to 0 for now
upper_ci <- 0             # upper bound for beta_1. Initialize to 0 for now.
lower_ci <- 0             # lower bound for beta_1. Initialize to 0 for now.
t_star <- qt(0.975, 38)   # Food for thought: why 38 instead of 40? What is t_star?

# Perform the simulation
for (i in 1:n_sim){
  y <- 1 + 1.2 * x + rnorm(40, sd = 2)
  lse <- lm(y ~ x)
  lse_output <- summary(lse)$coefficients
  se <- lse_output[2, 2]
  b1[i] <- lse_output[2, 1]
  upper_ci[i] <- b1[i] + t_star * se
  lower_ci[i] <- b1[i] - t_star * se
}
results <- as.data.frame(cbind(se, b1, upper_ci, lower_ci))
results
# remove unecessary variables from our workspace
rm(se, b1, upper_ci, lower_ci, x, n_sim, b1, t_star, lse, lse_out) 
```

i. Summarize the LS estimates of $\boldsymbol{\beta}_1$ (stored in `results$b1`). Does the sampling distribution agree with theory? 
```{r LS estimates summary, echo=TRUE}
# Inializing variables. Note b_1, upper_ci, lower_ci are vectors
x <- seq(0, 1, length = 40) 
n_sim <- 100              # number of simulations
b1 <- 0                   # n_sim many LS estimates of beta_1 (=1.2). Initialize to 0 for now
upper_ci <- 0             # upper bound for beta_1. Initialize to 0 for now.
lower_ci <- 0             # lower bound for beta_1. Initialize to 0 for now.
t_star <- qt(0.975, 38)   # Food for thought: why 38 instead of 40? What is t_star?

# Perform the simulation
for (i in 1:n_sim){
  y <- 1 + 1.2 * x + rnorm(40, sd = 2)
  lse <- lm(y ~ x)
  lse_output <- summary(lse)$coefficients
  se <- lse_output[2, 2]
  b1[i] <- lse_output[2, 1]
  upper_ci[i] <- b1[i] + t_star * se
  lower_ci[i] <- b1[i] - t_star * se
}
results <- as.data.frame(cbind(se, b1, upper_ci, lower_ci))
## inserting from above^

summary(results$b1)
sample_sd <- sd(results$b1)/sqrt(length(results$b1))
ci_lower = mean(results$b1) - 1.96*sample_sd
ci_upper = mean(results$b1) + 1.96*sample_sd
paste("Lower CI interval: ",ci_lower)
paste("Higher CI interval: ",ci_upper)
```
We see that the mean of the sampling distribution is 1.07 while the theoretical value should be 1.2. The estimate is not perfect but we do see that true value is captured within a 95% confidence interval of the sampiling mean, therefore we could say that the sampiling distribution agrees with theory.

ii.  How many of your 95% confidence intervals capture the true $\boldsymbol{\beta}_1$? Display your confidence intervals graphically. 
```{r Confidence Interval Summ, echo=TRUE}
sample_number = c(1:100)
p1 <- ggplot(results, aes(sample_number, b1)) + geom_point() + 
geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci))

p1 + ggtitle("Confidence Interval for Each Sample")
total_including <- sum(results$lower_ci<=1.2 & results$upper_ci>=1.2)
paste("Number of Confidence Intervals including true value: ",total_including)
```


